{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Techniques\n",
    "---\n",
    "- PCA (Principal Component Analysis) (Found the code)\n",
    "    - Calculates the amount of variances that each feature within the data set contributes to the target variable\n",
    "    - Multiple PCAs can be used but it would be depending on either an elbow method or what not\n",
    "- Boxplot: \n",
    "    - Conducting an outlier check to see within the standard ranges of the data sets\n",
    "    - May need to confirm if outliers actually influence the data sets to any significant value\n",
    "- Linear Regression:\n",
    "    - Calculating the influences assuming a linear scale of two factors (maybe shown in a multiple plot)\n",
    "- Clustering:\n",
    "    - Add on to PC components to see the influences and changes of the PC1 and PC2 based on the overall data points\n",
    "- Multicollinearity Findings(Found the code)\n",
    "    - Find each correlation between each features to itself and other features to demonstrate the relationships between them to reduce the amount. It finds features that are linearly correlated with each other so we won't need to include it\n",
    "    - Heatmap\n",
    "    (https://www.geeksforgeeks.org/multicollinearity-in-data/?ref=rp)\n",
    "    (https://vedexcel.com/how-to-create-a-covariance-matrix-in-python/#:~:text=Heatmap%20%E2%80%93%20Covariance%20Matrix%20in%20Python%20The%20plot,color%20represents%20the%20positive%20covariance%20between%20the%20variables.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset/Issued_Construction_Permits.csv').drop(['Day Issued','Link','Longitude','Latitude','Contractor Address 1','Contractor Address 2','Applicant Phone','Applicant Address 1','Applicant Address 2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Calculations to get the variance of each feature to reduce the amount of features for the dataset\n",
    "\"\"\"data_frame_standarized = scale(data set without nan (only numerical))\n",
    "\n",
    "covariance_matrix = PCA(n_components = total amount of features we currently have)\n",
    "\n",
    "covariance_matrix.fit(data_frame_standarized)\n",
    "\n",
    "variance = covar_matrix.explained_variance_ratio_\n",
    "\n",
    "var=np.cumsum(np.round(covar_matrix.explained_variance_ratio_, decimals=3)*100)\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(30,100.5)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "plt.plot(var)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the multicollinearity of the data sets to reduce features because there are relationships between the multiple features\n",
    "# Checking if the covariance matrix is the same as the PCA and Multicollinearity calculations and figuring out\n",
    "\n",
    "\"\"\"from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "  \n",
    "# creating dummies for gender\n",
    "data['Gender'] = data['Gender'].map({'Male':0, 'Female':1})\n",
    "  \n",
    "# the independent variables set\n",
    "X = data[['Gender', 'Height', 'Weight']]\n",
    "  \n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                          for i in range(len(X.columns))]\n",
    "\n",
    "sns.heatmap(covarianceMatrix, annot=True, fmt='g')\n",
    "plt.show()\n",
    "\n",
    "#Calculate the VID for each column and then comparing it\n",
    "[vif(data[iv].values, index) for index in range(len(iv))]\n",
    "  \n",
    "print(vif_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d23624b13311fb1af1c90e93df5b4884b185f1d04f2264343d59e90a86c3d0b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
