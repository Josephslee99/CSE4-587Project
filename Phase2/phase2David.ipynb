{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Algorithms/Visualizations: Apply 5 different significant and relevant\n",
    "algorithms (ML, MR, and/or statistical models) to your data and create visualizations for\n",
    "the results. \n",
    "    - For 487 students: at least 1 of the 5 algorithms must be one that was not\n",
    "discussed in class. \n",
    "    - For 587 students: at least 2 must be from outside of class. \n",
    "    - These outside algorithms can come from the class textbooks, or other sources. Cite the appropriate sources for each outside algorithm you choose to apply.\n",
    "2. Explanation and Analysis: For each of the 5 above algorithms, provide\n",
    "justification for why you chose the particular algorithm, and discuss the effectiveness of\n",
    "the algorithm when applied to your data to answer questions related to your problem\n",
    "statement. \n",
    "    - This should include discussion of any relevant metrics for demonstrating\n",
    "model effectiveness, as well as any intelligence you were able to gain from application of\n",
    "the algorithm to your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the algorithms that is being used outside of class is Random Forest machine learning algorithm. We are also incorporating Bagging ensembler learning which is basically randomly splitting the data set into different versions with different entries selected and from there, the Random Forest is created through the best model of all the occurrences. That way, it will optimize the model to better predict the values. We wanted to use regular Decision Tree Regressors in the beginning; however, Random Forest Regressor was used in the end because Decision Trees tend to get overfitted quite easily so we wanted to apply Bagging to counteract that as well as including a training and testing portion. \n",
    "\n",
    "https://medium.com/nerd-for-tech/bootstrap-aggregating-and-random-forest-model-9460e235537\n",
    "https://www.geeksforgeeks.org/random-forest-regression-in-python/\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\david\\\\Documents\\\\University at Buffalo\\\\Masters\\\\Fall 2022\\\\CSE 587\\\\CSE4-587Project\\\\Dataset\\\\ICP_Residential_Austin2017up.csv')\n",
    "# Choosing the columns\n",
    "data_columns_for_pca = data[[\n",
    "'Remodel Repair SQFT', 'Total New Add SQFT','Total Valuation Remodel', 'Number Of Floors', 'Total Job Valuation',\n",
    "'Total Lot SQFT']]\n",
    "\n",
    "#Replacing the empty space with NaN and then deleting all the NaN\n",
    "data_columns_for_pca = data_columns_for_pca.replace(r'^s*$', float('NaN'))\n",
    "data_columns_for_pca.dropna(inplace = True)\n",
    "print(data_columns_for_pca.shape)\n",
    "\n",
    "#Selecting the columns that are categorical and converting it into numerical \n",
    "data_columns_for_pca = data_columns_for_pca[data_columns_for_pca['Total Job Valuation']>1000]\n",
    "print(data_columns_for_pca.shape)\n",
    "\n",
    "\n",
    "data_target = data_columns_for_pca['Total Job Valuation']\n",
    "data_columns_for_pca.drop(columns='Total Job Valuation', inplace=True)\n",
    "\n",
    "X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(data_columns_for_pca, data_target, test_size=0.2, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_max5 = DecisionTreeRegressor(max_depth=4)\n",
    "dt_max5.fit(X_train_dt, y_train_dt)\n",
    "\n",
    "y_dt_max5 = dt_max5.predict(X_test_dt)\n",
    "plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(dt_max5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_dt = metrics.mean_absolute_error(y_test_dt, y_dt_max5)\n",
    "mse_dt = metrics.mean_squared_error(y_test_dt, y_dt_max5)\n",
    "rmse_dt = np.sqrt(mse_dt) # or mse**(0.5)  \n",
    "r2_dt = metrics.r2_score(y_test_dt,y_dt_max5)\n",
    "r2_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = dt_max5.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos, np.array(data_columns_for_pca.columns)[sorted_idx])\n",
    "plt.title(\"Feature Importance Decision Tree (MDI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "rf_regression = RandomForestRegressor(bootstrap=True, max_depth=5, criterion=\"squared_error\") # was 'squared_error', changed to 'mse' to run it for curr ver\n",
    "rf_regression.fit(X_train_dt, y_train_dt)\n",
    "\n",
    "filename = 'random_forest.sav'\n",
    "pickle.dump(rf_regression, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf_max4 = rf_regression.predict(X_test_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(rf_regression.estimators_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_rf = metrics.mean_absolute_error(y_test_dt, y_rf_max4)\n",
    "mse_rf = metrics.mean_squared_error(y_test_dt, y_rf_max4)\n",
    "rmse_rf = np.sqrt(mse_rf) # or mse**(0.5)  \n",
    "r2_rf = metrics.r2_score(y_test_dt,y_rf_max4)\n",
    "r2_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rf_regression.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos, np.array(data_columns_for_pca.columns)[sorted_idx])\n",
    "plt.title(\"Random Forest (MDI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_max = GradientBoostingRegressor(criterion=\"squared_error\") # 'squared_error' => 'mse'\n",
    "gb_max.fit(X_train_dt, y_train_dt)\n",
    "\n",
    "filename = 'GradientBoosting.sav'\n",
    "pickle.dump(gb_max, open(filename, 'wb'))\n",
    "\n",
    "y_gb_max = gb_max.predict(X_test_dt)\n",
    "plt.figure(figsize=(25,20))\n",
    "\n",
    "mae_gb = metrics.mean_absolute_error(y_test_dt, y_gb_max)\n",
    "mse_gb = metrics.mean_squared_error(y_test_dt, y_gb_max)\n",
    "rmse_gb = np.sqrt(mse_gb) # or mse**(0.5)  \n",
    "r2_gb = metrics.r2_score(y_test_dt,y_gb_max)\n",
    "r2_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = gb_max.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos, np.array(data_columns_for_pca.columns)[sorted_idx])\n",
    "plt.title(\"Gradient Boosting (MDI)\")\n",
    "\n",
    "# This figure is representing the features of importance to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "plt.xlabel('Total New Add SQFT')\n",
    "plt.ylabel('Total Job Valuation')\n",
    "plt.title('Random Forest Predictions Against Actual Data Points')\n",
    "plt.scatter(X_test_dt.loc[:,\"Total New Add SQFT\"], y_test_dt)\n",
    "plt.scatter(X_test_dt.loc[:,\"Total New Add SQFT\"], y_rf_max4, color=\"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_comparison = [mae_rf, mae_dt, mae_gb]\n",
    "mse_comparison = [mse_rf, mse_dt, mse_gb]\n",
    "rmse_comparison = [rmse_rf, rmse_dt, rmse_gb]\n",
    "r2_comparison = [r2_rf, r2_dt, r2_gb]\n",
    "\n",
    "width = 0.25\n",
    "\n",
    "labels = [\"Random Forest\", \"Decision Tree\", \"Gradient Boosting\"]\n",
    "x_labels = np.arange(len(labels))\n",
    "plt.bar(x_labels - 0.125, mae_comparison, width=width)\n",
    "plt.bar(x_labels + 0.125, rmse_comparison, width=width)\n",
    "plt.xticks(x_labels, labels)\n",
    "plt.ylabel(\"Numerical Values\")\n",
    "plt.title(\"RMSE vs MAE\")\n",
    "\n",
    "# RMSE is highest one\n",
    "# Notation here: the MSE values are wayyyyy tooo high! Unable to portray it on the same graph!\n",
    "# Need to double check the R2 values and the data that is being used for the models because it seem to be that they aren't being done properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Random Forest\", \"Decision Tree\", \"Gradient Boosting\"]\n",
    "x_labels = np.arange(len(labels))\n",
    "plt.bar(x_labels, r2_comparison, width=width)\n",
    "plt.xticks(x_labels, labels)\n",
    "plt.ylabel(\"Numerical Values\")\n",
    "plt.title(\"R2 Comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results of sklearn.metrics for Decision Tree:\")\n",
    "print(\"MAE for Decision Tree:\", mae_dt)\n",
    "print(\"MSE for Decision Tree:\", mse_dt)\n",
    "print(\"RMSE for Decision Tree:\", rmse_dt)\n",
    "print(\"R-Squared for Decision Tree:\", r2_dt)\n",
    "print(\"\")\n",
    "print(\"Results of sklearn.metrics for Random Forest:\")\n",
    "print(\"MAE for Random Forest:\", mae_rf)\n",
    "print(\"MSE for Random Forest:\", mse_rf)\n",
    "print(\"RMSE for Random Forest:\", rmse_rf)\n",
    "print(\"R-Squared for Random Forest:\", r2_rf)\n",
    "print(\"\")\n",
    "print(\"Results of sklearn.metrics for Gradient Boosting:\")\n",
    "print(\"MAE for Gradient Boosting:\", mae_gb)\n",
    "print(\"MSE for Gradient Boosting:\", mse_gb)\n",
    "print(\"RMSE for Gradient Boosting:\", rmse_gb)\n",
    "print(\"R-Squared for Gradient Boosting:\", r2_gb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4eedd9fc418f36e2614580cbf31de2386521dabe9ec8a80375aa0fadc40a33bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
